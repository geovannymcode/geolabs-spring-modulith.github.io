# GuÃ­a CQRS Spring Modulith - Parte 3: Observabilidad y Deployment

## Continuando desde la Parte 2

En la Parte 2 implementamos completamente el patrÃ³n CQRS con Spring Modulith. Ahora vamos a agregar observabilidad, automatizaciÃ³n y deployment para tener un sistema completo listo para producciÃ³n.

## Tabla de Contenidos - Parte 3
1. [Observabilidad con Zipkin](#observabilidad-con-zipkin)
2. [AutomatizaciÃ³n con Taskfile](#automatizaciÃ³n-con-taskfile)
3. [Eventos Externos con Kafka](#eventos-externos-con-kafka)
4. [Testing de IntegraciÃ³n Avanzado](#testing-de-integraciÃ³n-avanzado)
5. [Deployment con Docker](#deployment-con-docker)
6. [Demo Final](#demo-final)
7. [ConclusiÃ³n del Workshop](#conclusiÃ³n-del-workshop)

## Observabilidad con Zipkin

### Â¿QuÃ© es Observabilidad?

**DefiniciÃ³n simple**: La capacidad de entender quÃ© estÃ¡ pasando dentro de tu aplicaciÃ³n mientras funciona.

**AnalogÃ­a**: Es como tener "rayos X" de tu aplicaciÃ³n para ver cÃ³mo fluyen las peticiones y datos.

### Â¿Por quÃ© Necesitamos Observabilidad en MÃ³dulos?

**Problema sin observabilidad**:
```java
// Usuario reporta: "AgreguÃ© un review pero no se actualiza el promedio"
// Â¿DÃ³nde estÃ¡ el problema?
// - Â¿Se guardÃ³ el review?
// - Â¿Se publicÃ³ el evento?
// - Â¿Se procesÃ³ el evento?
// - Â¿Se actualizÃ³ la vista?
// NO LO SABEMOS
```

**Con observabilidad**:
```
Traza completa:
1. POST /products/123/reviews â†’ 200ms
2. ProductCommandService.addReview â†’ 50ms
3. ProductRepository.save â†’ 30ms
4. EventPublisher.publishEvent â†’ 5ms
5. ProductEventHandler.on â†’ 80ms â† AQUÃ FALLÃ“
6. ProductViewRepository.save â†’ NO EJECUTADO
```

### Â¿QuÃ© es Zipkin?

**DefiniciÃ³n**: Zipkin es una herramienta que rastrea peticiones a travÃ©s de sistemas distribuidos.

**Â¿Para quÃ© sirve?**
- Ver el tiempo que toma cada operaciÃ³n
- Identificar cuellos de botella
- Debuggear problemas de performance
- Entender el flujo de datos entre mÃ³dulos

**Â¿Por quÃ© Zipkin y no logs?**

**Logs tradicionales**:
```
2024-01-15 10:30:01 INFO ProductService - Creating product
2024-01-15 10:30:01 INFO EventPublisher - Publishing event
2024-01-15 10:30:02 INFO ProductHandler - Processing event
```
**Problema**: Â¿QuÃ© evento pertenece a quÃ© producto? Â¿CuÃ¡nto tiempo tomÃ³ en total?

**Zipkin (Distributed Tracing)**:
```
Trace ID: abc123
â”œâ”€ Span 1: ProductService.createProduct [100ms]
â”œâ”€ Span 2: ProductRepository.save [30ms]
â””â”€ Span 3: ProductEventHandler.on [70ms]
```
**Ventaja**: Ves el flujo completo con tiempos exactos y relaciones.

### Â¿CÃ³mo Funciona la Trazabilidad?

**Conceptos clave**:

#### 1. Trace (Traza)
**DefiniciÃ³n**: El viaje completo de una peticiÃ³n a travÃ©s de tu sistema.

**Ejemplo**: "Crear un producto con review"
```
Trace: "POST /products + POST /reviews"
â”œâ”€ Crear producto
â”œâ”€ Publicar evento ProductCreated  
â”œâ”€ Actualizar vista de producto
â”œâ”€ Agregar review
â”œâ”€ Publicar evento ProductReviewed
â””â”€ Actualizar estadÃ­sticas
```

#### 2. Span
**DefiniciÃ³n**: Una operaciÃ³n individual dentro de una traza.

**Ejemplo**: "Guardar en base de datos"
- Inicio: 10:30:01.100
- Fin: 10:30:01.130
- DuraciÃ³n: 30ms
- OperaciÃ³n: ProductRepository.save

#### 3. Trace ID y Span ID
**DefiniciÃ³n**: Identificadores Ãºnicos para correlacionar operaciones.

**AnalogÃ­a**: Como el nÃºmero de seguimiento de un paquete que te permite ver todos los pasos del envÃ­o.

### ConfiguraciÃ³n de Trazabilidad

#### Paso 1: Agregar Dependencias de Observabilidad

```xml
<!-- pom.xml - Agregar estas dependencias para observabilidad -->
<dependencies>
    <!-- Las dependencias existentes... -->
    
    <!-- 
    Â¿QuÃ© es? Puente entre Spring y Brave (biblioteca de tracing)
    Â¿Para quÃ©? Permite que Spring Boot genere automÃ¡ticamente trazas
    Â¿Sin esto? No habrÃ­a trazabilidad entre mÃ©todos
    -->
    <dependency>
        <groupId>io.micrometer</groupId>
        <artifactId>micrometer-tracing-bridge-brave</artifactId>
    </dependency>
    
    <!-- 
    Â¿QuÃ© es? Cliente que envÃ­a trazas a Zipkin
    Â¿Para quÃ©? Transporta las trazas desde tu app hasta Zipkin UI
    Â¿Sin esto? Las trazas se quedan en memoria y no las ves
    -->
    <dependency>
        <groupId>io.zipkin.reporter2</groupId>
        <artifactId>zipkin-reporter-brave</artifactId>
    </dependency>
    
    <!-- 
    Â¿QuÃ© es? Endpoints de monitoreo de Spring Boot
    Â¿Para quÃ©? Expone /actuator/health, /actuator/modulith, etc.
    Â¿Sin esto? No puedes ver el estado de tu aplicaciÃ³n externamente
    -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
</dependencies>
```

#### Paso 2: ConfiguraciÃ³n Explicada

```yaml
# src/main/resources/application.yml - Agregar configuraciÃ³n de observabilidad
management:
  endpoints:
    web:
      exposure:
        # Â¿QuÃ© hace? Expone endpoints Ãºtiles vÃ­a HTTP
        # Â¿Por quÃ© estos? health=estado, modulith=informaciÃ³n de mÃ³dulos
        include: health,info,metrics,modulith
  endpoint:
    health:
      # Â¿QuÃ© hace? Muestra detalles de salud (BD, Kafka, etc.)
      # Â¿Por quÃ©? Para debugging rÃ¡pido sin logs
      show-details: always
    modulith:
      # Â¿QuÃ© hace? Endpoint especÃ­fico de Spring Modulith
      # Â¿Para quÃ©? Ver quÃ© mÃ³dulos tienes y sus dependencias
      enabled: true
  
  # ConfiguraciÃ³n de trazas
  tracing:
    sampling:
      # Â¿QuÃ© es? Porcentaje de peticiones que se rastrean
      # Â¿Por quÃ© 1.0? En desarrollo queremos ver todo
      # Â¿En producciÃ³n? 0.1 (10%) para no saturar
      probability: 1.0
  zipkin:
    tracing:
      # Â¿QuÃ© hace? URL donde Zipkin recibe las trazas
      # Â¿Por quÃ© esta URL? Es el endpoint estÃ¡ndar de Zipkin
      endpoint: http://localhost:9411/api/v2/spans

# Logging para ver IDs de traza en consola
logging:
  pattern:
    # Â¿QuÃ© hace? Agrega traceId y spanId a cada log
    # Â¿Para quÃ©? Correlacionar logs con trazas en Zipkin
    level: "%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]"
```

### Â¿QuÃ© InformaciÃ³n Nos Da el Endpoint de MÃ³dulos?

```bash
# Ver informaciÃ³n de mÃ³dulos
curl http://localhost:8080/actuator/modulith
```

**Respuesta explicada**:
```json
{
  "modules": [
    {
      "name": "products",                    // Nombre del mÃ³dulo
      "basePackage": "com.example.store.products",  // Paquete raÃ­z
      "dependencies": ["common"],            // De quÃ© mÃ³dulos depende
      "exposedTypes": [                      // APIs pÃºblicas
        "ProductService", 
        "Product"
      ]
    }
  ],
  "violations": []                           // Reglas arquitectÃ³nicas violadas
}
```

**Â¿Para quÃ© sirve esto?**
- **DocumentaciÃ³n automÃ¡tica**: Siempre actualizada
- **Debugging de dependencias**: Ver quiÃ©n depende de quiÃ©n
- **ValidaciÃ³n de arquitectura**: Detectar violaciones
- **Onboarding de nuevos desarrolladores**: Entender la estructura

## AutomatizaciÃ³n con Taskfile

### Â¿QuÃ© es Taskfile?

**DefiniciÃ³n**: Taskfile es una herramienta de automatizaciÃ³n que usa YAML en lugar de Makefiles o scripts bash.

**AnalogÃ­a**: Es como tener un "control remoto" para tu proyecto donde cada botÃ³n ejecuta una secuencia de comandos.

### Â¿Por QuÃ© Taskfile en Lugar de Scripts Bash?

#### Problemas con Scripts Bash

**1. Multiplataforma**:
```bash
# archivo.sh - Solo funciona en Linux/Mac
#!/bin/bash
./mvnw clean test

# archivo.bat - Solo funciona en Windows  
@echo off
mvnw.cmd clean test
```

**2. Dependencias manuales**:
```bash
# build.sh
./test.sh          # Â¿QuÃ© pasa si test.sh falla?
./compile.sh       # Â¿Se ejecuta igual?
./package.sh       # Â¿En quÃ© orden van?
```

**3. Manejo de errores complejo**:
```bash
# Complejo de leer y mantener
set -e
if ! ./mvnw test; then
    echo "Tests failed"
    exit 1
fi
if ! docker build .; then
    echo "Build failed"  
    exit 1
fi
```

#### Ventajas de Taskfile

**1. Multiplataforma automÃ¡tico**:
```yaml
# Funciona igual en Windows, Linux, Mac
vars:
  MVNW: '{{if eq .GOOS "windows"}}mvnw.cmd{{else}}./mvnw{{end}}'
```

**2. Dependencias declarativas**:
```yaml
build:
  deps: [test]        # Ejecuta 'test' antes de 'build'
  cmds:
    - "{{.MVNW}} package"
```

**3. Sintaxis clara**:
```yaml
# FÃ¡cil de leer y entender
test:
  desc: "Ejecuta todos los tests"
  cmds:
    - "{{.MVNW}} clean verify"
```

### ImplementaciÃ³n del Taskfile

Crea `Taskfile.yml` en la raÃ­z del proyecto:

```yaml
# Taskfile.yml
version: '3'

# Variables globales - Reutilizables en todo el archivo
vars:
  GOOS: "{{default OS .GOOS}}"                    # Sistema operativo
  MVNW: '{{if eq .GOOS "windows"}}mvnw.cmd{{else}}./mvnw{{end}}'  # Maven wrapper correcto
  DC_DIR: "deployment"                            # Directorio de Docker Compose
  APP_NAME: "store-cqrs"                         # Nombre de la aplicaciÃ³n

tasks:
  
  # =====================================
  # TAREAS DE DESARROLLO
  # =====================================
  
  default:
    # Â¿QuÃ© hace? Se ejecuta cuando solo escribes 'task'
    # Â¿Por quÃ©? AcciÃ³n mÃ¡s comÃºn = ejecutar tests
    desc: "Ejecuta tests y verifica mÃ³dulos"
    cmds:
      - task: test

  format:
    # Â¿QuÃ© hace? Formatea el cÃ³digo con Spotless
    # Â¿Por quÃ©? Mantiene estilo consistente sin discusiones
    desc: "Formatea el cÃ³digo"
    cmds:
      - "{{.MVNW}} spotless:apply"
  
  test:
    # Â¿QuÃ© hace? Ejecuta todos los tests
    # Â¿Por quÃ© deps? Siempre formatea antes de testear
    desc: "Ejecuta todos los tests"
    deps: [format]
    cmds:
      - "{{.MVNW}} clean verify"
  
  test:modulith:
    # Â¿QuÃ© hace? Solo verifica que la estructura modular sea correcta
    # Â¿CuÃ¡ndo usar? Para debugging rÃ¡pido de arquitectura
    desc: "Verifica estructura modular"
    cmds:
      - "{{.MVNW}} test -Dtest=ModularityTest"
      - echo "âœ… Estructura modular verificada"

  # =====================================
  # DOCUMENTACIÃ“N
  # =====================================
  
  docs:
    # Â¿QuÃ© hace? Genera diagramas de la estructura modular
    # Â¿Por quÃ©? DocumentaciÃ³n siempre actualizada automÃ¡ticamente
    desc: "Genera documentaciÃ³n de mÃ³dulos"
    cmds:
      - "{{.MVNW}} test -Dtest=ModularityTest"
      - echo "ğŸ“š DocumentaciÃ³n generada en target/spring-modulith-docs/"

  # =====================================
  # CONSTRUCCIÃ“N
  # =====================================
  
  build:
    # Â¿QuÃ© hace? Compila y empaqueta la aplicaciÃ³n
    # Â¿Por quÃ© deps? Asegura que tests pasan antes de compilar
    desc: "Construye la aplicaciÃ³n"
    deps: [test]
    cmds:
      - "{{.MVNW}} clean package -DskipTests"
  
  build:image:
    # Â¿QuÃ© hace? Crea imagen Docker de la aplicaciÃ³n
    # Â¿Por quÃ©? Para despliegue containerizado
    desc: "Construye imagen Docker"
    deps: [build]
    cmds:
      - "{{.MVNW}} spring-boot:build-image -DskipTests"
      - echo "ğŸ³ Imagen construida: {{.APP_NAME}}:latest"

  # =====================================
  # INFRAESTRUCTURA
  # =====================================
  
  infra:start:
    # Â¿QuÃ© hace? Inicia solo los servicios base (BD, Zipkin, Kafka)
    # Â¿Por quÃ© separado? Para desarrollo local sin la app
    desc: "Inicia servicios base (PostgreSQL, Zipkin, Kafka)"
    cmds:
      - docker compose -f "{{.DC_DIR}}/docker-compose.yml" up -d postgres zipkin kafka
      - echo "ğŸš€ Esperando servicios..."
      - task: infra:wait
      - echo "âœ… Infraestructura lista"
  
  infra:wait:
    # Â¿QuÃ© hace? Espera a que todos los servicios estÃ©n listos
    # Â¿Por quÃ©? Evita errores de "connection refused"
    desc: "Espera a que los servicios estÃ©n listos"
    cmds:
      - |
        echo "â³ Esperando PostgreSQL..."
        timeout 60 sh -c 'until docker compose -f {{.DC_DIR}}/docker-compose.yml exec -T postgres pg_isready -U store_user; do sleep 1; done'
        echo "â³ Esperando Zipkin..."
        timeout 30 sh -c 'until curl -f http://localhost:9411/health; do sleep 1; done'
        echo "â³ Esperando Kafka..."
        timeout 30 sh -c 'until docker compose -f {{.DC_DIR}}/docker-compose.yml exec -T kafka kafka-topics.sh --bootstrap-server localhost:9092 --list; do sleep 1; done'
    silent: true

  infra:stop:
    desc: "Detiene todos los servicios"
    cmds:
      - docker compose -f "{{.DC_DIR}}/docker-compose.yml" down

  infra:clean:
    desc: "Detiene servicios y limpia volÃºmenes"
    cmds:
      - docker compose -f "{{.DC_DIR}}/docker-compose.yml" down -v
      - docker system prune -f

  # =====================================
  # DESARROLLO LOCAL
  # =====================================
  
  dev:
    # Â¿QuÃ© hace? Prepara todo para desarrollo local
    # Â¿QuÃ© incluye? Solo infraestructura, la app se ejecuta con IDE
    desc: "Inicia entorno de desarrollo"
    cmds:
      - task: infra:start
      - echo "ğŸ”§ Entorno listo. Ejecuta: {{.MVNW}} spring-boot:run"
      - echo "ğŸ“Š Zipkin: http://localhost:9411"
      - echo "ğŸ˜ PostgreSQL: localhost:5432"
      - echo "ğŸ“¡ Kafka: localhost:9092"

  # =====================================
  # DEMO COMPLETO
  # =====================================
  
  demo:
    desc: "Demo completo con todos los servicios"
    cmds:
      - task: build:image
      - docker compose -f "{{.DC_DIR}}/docker-compose.yml" up -d
      - task: infra:wait
      - echo "ğŸ‰ Demo listo!"
      - echo "ğŸŒ AplicaciÃ³n: http://localhost:8080"
      - echo "â¤ï¸ Health Check: http://localhost:8080/actuator/health"
      - echo "ğŸ—‚ï¸ MÃ³dulos: http://localhost:8080/actuator/modulith"
      - echo "ğŸ“Š Zipkin: http://localhost:9411"

  demo:stop:
    desc: "Detiene el demo"
    cmds:
      - docker compose -f "{{.DC_DIR}}/docker-compose.yml" down

  demo:clean:
    desc: "Limpia completamente el demo"
    cmds:
      - docker compose -f "{{.DC_DIR}}/docker-compose.yml" down -v
      - docker image rm {{.APP_NAME}}:latest || true
```

### Â¿CÃ³mo se Usa en la PrÃ¡ctica?

```bash
# Comandos mÃ¡s comunes en desarrollo
task                    # = task default = tests
task dev               # Prepara entorno, luego usar IDE
task test:modulith     # Solo verificar arquitectura
task docs              # Generar documentaciÃ³n
task build             # Compilar aplicaciÃ³n
task infra:start       # Solo servicios base
task demo              # Demo completo
```

## Eventos Externos con Kafka

### Â¿QuÃ© es Kafka?

**DefiniciÃ³n**: Apache Kafka es una plataforma de streaming de eventos distribuida.

**AnalogÃ­a**: Es como un "buzÃ³n de correo masivo" donde:
- Los **productores** envÃ­an mensajes (eventos)
- Los **tÃ³picos** organizan los mensajes por tema
- Los **consumidores** leen mensajes que les interesan

### Â¿Por QuÃ© Necesitamos Eventos Externos?

#### Problema: ComunicaciÃ³n con Sistemas Externos

**Escenario**: Tu aplicaciÃ³n de productos debe notificar a otros sistemas cuando algo importante pasa.

**Sistemas que pueden interesarse**:
- **Sistema de inventario**: Actualizar stock cuando se vende
- **Sistema de recomendaciones**: Ajustar algoritmos con nuevos reviews
- **Sistema de analytics**: Registrar mÃ©tricas de productos
- **Sistema de notificaciones**: Enviar emails de nuevos productos

#### Opciones de ComunicaciÃ³n

**âŒ OpciÃ³n 1: Llamadas HTTP Directas**
```java
// Problema: Alto acoplamiento
productService.createProduct(...);
httpClient.post("http://inventory-service/update");      // Â¿Y si estÃ¡ caÃ­do?
httpClient.post("http://analytics-service/track");       // Â¿Y si es lento?
httpClient.post("http://recommendations-service/sync");  // Â¿Y si cambia la URL?
```

**âŒ OpciÃ³n 2: Base de Datos Compartida**
```java
// Problema: Acoplamiento de datos
productRepository.save(product);
sharedDatabase.insert("inventory_updates", ...);  // Todos acceden a la misma BD
sharedDatabase.insert("analytics_events", ...);   // Violates microservices principles
```

**âœ… OpciÃ³n 3: Eventos con Kafka**
```java
// SoluciÃ³n: Bajo acoplamiento
productService.createProduct(...);
eventPublisher.publishEvent(new ProductCreated(...));  // Solo publicar
// Otros sistemas se suscriben si les interesa
// No conoces quiÃ©n consume, no es tu problema
```

### Â¿CÃ³mo Funciona Kafka?

#### Conceptos Fundamentales

**1. TÃ³pico (Topic)**
**DefiniciÃ³n**: Un canal de comunicaciÃ³n para un tipo especÃ­fico de evento.

**Ejemplo**:
```
TÃ³pico: "products.created"
â”œâ”€ Evento 1: {id: "123", name: "iPhone", price: 999}
â”œâ”€ Evento 2: {id: "124", name: "MacBook", price: 1999}
â””â”€ Evento 3: {id: "125", name: "iPad", price: 599}
```

**2. Productor (Producer)**
**DefiniciÃ³n**: AplicaciÃ³n que envÃ­a eventos a un tÃ³pico.

**En nuestro caso**: La aplicaciÃ³n Spring Modulith

**3. Consumidor (Consumer)**
**DefiniciÃ³n**: AplicaciÃ³n que lee eventos de un tÃ³pico.

**Ejemplos**:
- Servicio de inventario lee "products.created"
- Servicio de analytics lee "products.reviewed"
- Servicio de notificaciones lee ambos

#### Ventajas de Kafka vs Otras Opciones

| Aspecto | HTTP Directo | Base de Datos | Kafka |
|---------|-------------|---------------|-------|
| **Acoplamiento** | Alto | Alto | Bajo |
| **Disponibilidad** | Si un servicio cae, todo falla | BD puede saturarse | Resiliente |
| **Escalabilidad** | Limitada | Limitada | Muy alta |
| **AuditorÃ­a** | DifÃ­cil | Manual | AutomÃ¡tica |
| **Reprocessing** | No | DifÃ­cil | FÃ¡cil |

### ConfiguraciÃ³n de Kafka

#### Paso 1: Agregar Dependencias de Kafka

```xml
<!-- pom.xml - Agregar dependencias de Kafka -->
<dependency>
    <!-- Â¿QuÃ© es? Cliente oficial de Kafka para Spring -->
    <!-- Â¿Para quÃ©? Enviar y recibir mensajes de Kafka -->
    <!-- Â¿Sin esto? No hay comunicaciÃ³n con Kafka -->
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

<dependency>
    <!-- Â¿QuÃ© es? IntegraciÃ³n entre Spring Modulith y Kafka -->
    <!-- Â¿Para quÃ©? Publicar eventos internos automÃ¡ticamente a Kafka -->
    <!-- Â¿Sin esto? TendrÃ­as que publicar manualmente a Kafka -->
    <groupId>org.springframework.modulith</groupId>
    <artifactId>spring-modulith-events-kafka</artifactId>
</dependency>
```

#### Paso 2: ConfiguraciÃ³n Explicada

```yaml
# application.yml - Agregar configuraciÃ³n de Kafka
spring:
  kafka:
    # Â¿QuÃ© es? DirecciÃ³n del cluster de Kafka
    # Â¿Por quÃ© localhost:9092? Puerto estÃ¡ndar de Kafka
    bootstrap-servers: localhost:9092
    
    producer:
      # Â¿QuÃ© hace? Serializa la clave del mensaje
      # Â¿Por quÃ© String? Claves simples como "product-123"
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      
      # Â¿QuÃ© hace? Convierte objetos Java a JSON
      # Â¿Por quÃ© JSON? Formato estÃ¡ndar, legible, interoperable
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    
    consumer:
      # Â¿QuÃ© es? Identificador del grupo de consumidores
      # Â¿Para quÃ©? Kafka garantiza que solo uno del grupo procese cada mensaje
      group-id: store-cqrs
      
      # Â¿QuÃ© hace? Lee claves como String
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      
      # Â¿QuÃ© hace? Convierte JSON de vuelta a objetos Java
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      
      properties:
        # Â¿QuÃ© es? Paquetes Java confiables para deserializaciÃ³n
        # Â¿Por quÃ©? Seguridad: evita crear objetos de paquetes maliciosos
        spring.json.trusted.packages: "com.example.store"

  modulith:
    events:
      externalization:
        # Â¿QuÃ© hace? Habilita publicaciÃ³n automÃ¡tica a sistemas externos
        # Â¿CÃ³mo? Eventos marcados con @Externalized van a Kafka
        enabled: true
```

#### Paso 3: Configurar QuÃ© Eventos Van a Kafka

```java
// src/main/java/com/example/store/config/EventsConfig.java
package com.example.store.config;

import com.example.store.products.command.ProductEvents.ProductCreated;
import com.example.store.products.command.ProductEvents.ProductReviewed;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.modulith.events.config.EventExternalizationConfiguration;

/**
 * ConfiguraciÃ³n para decidir quÃ© eventos se publican externamente.
 */
@Configuration
public class EventsConfig {
    
    @Bean
    EventExternalizationConfiguration eventExternalizationConfiguration() {
        return EventExternalizationConfiguration.externalizing()
            // ProductCreated va al tÃ³pico "products.created"
            .route(ProductCreated.class).to("products.created")
            
            // ProductReviewed va al tÃ³pico "products.reviewed"  
            .route(ProductReviewed.class).to("products.reviewed")
            
            // ProductUpdated NO se incluye = solo interno
            .build();
    }
}
```

**Â¿Por quÃ© algunos eventos van a Kafka y otros no?**

**A Kafka** (eventos que interesan a otros sistemas):
- `ProductCreated`: Inventario necesita saber para crear stock
- `ProductReviewed`: Analytics necesita para mÃ©tricas

**Solo internos** (eventos de implementaciÃ³n):
- `ProductUpdated`: Solo le importa a nuestra aplicaciÃ³n

### Â¿QuÃ© Pasa Cuando Publicas un Evento?

**Flujo completo**:

1. **Comando ejecutado**:
   ```java
   productService.createProduct("iPhone", ...);
   ```

2. **Evento publicado internamente**:
   ```java
   eventPublisher.publishEvent(new ProductCreated(...));
   ```

3. **Spring Modulith actÃºa**:
   - Busca listeners internos â†’ Ejecuta `ProductEventHandler.on()`
   - Ve configuraciÃ³n â†’ EnvÃ­a tambiÃ©n a Kafka

4. **En Kafka**:
   ```json
   TÃ³pico: "products.created"
   Mensaje: {
     "id": "123",
     "name": "iPhone 15",
     "price": 999.99,
     "category": "Electronics"
   }
   ```

5. **Sistemas externos**:
   - Servicio de inventario consume y crea stock inicial
   - Servicio de analytics registra nueva categoria
   - Servicio de recomendaciones actualiza algoritmos

## Testing de IntegraciÃ³n Avanzado

### Testing con Kafka

Para testear la integraciÃ³n con Kafka, necesitamos tests que verifiquen que los eventos se publican correctamente.

```java
// src/test/java/com/example/store/events/KafkaIntegrationTest.java
package com.example.store.events;

import com.example.store.products.command.Product.ProductIdentifier;
import com.example.store.products.command.ProductCommandService;
import com.example.store.products.command.ProductEvents.ProductCreated;
import lombok.RequiredArgsConstructor;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.junit.jupiter.api.Test;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.listener.KafkaMessageListenerContainer;
import org.springframework.kafka.listener.MessageListener;
import org.springframework.kafka.support.serializer.JsonDeserializer;
import org.springframework.kafka.test.EmbeddedKafkaBroker;
import org.springframework.kafka.test.context.EmbeddedKafka;
import org.springframework.kafka.test.utils.KafkaTestUtils;
import org.springframework.test.annotation.DirtiesContext;

import java.math.BigDecimal;
import java.time.Duration;
import java.util.Map;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;

import static org.assertj.core.api.Assertions.assertThat;

/**
 * Test de integraciÃ³n para verificar que eventos se publican a Kafka.
 * 
 * Â¿QuÃ© hace @EmbeddedKafka?
 * - Levanta un broker de Kafka real para testing
 * - No necesita Docker durante tests
 * - Aislado por test
 */
@SpringBootTest
@EmbeddedKafka(topics = {"products.created", "products.reviewed"})
@DirtiesContext  // Limpia contexto despuÃ©s de cada test
@RequiredArgsConstructor
class KafkaIntegrationTest {
    
    private final ProductCommandService productCommandService;
    private final EmbeddedKafkaBroker embeddedKafka;
    
    @Test
    void shouldPublishProductCreatedEventToKafka() throws InterruptedException {
        // Arrange: Configurar consumidor de Kafka para test
        Map<String, Object> consumerProps = KafkaTestUtils.consumerProps("test-group", "true", embeddedKafka);
        consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        consumerProps.put(JsonDeserializer.TRUSTED_PACKAGES, "com.example.store");
        
        var consumerFactory = new DefaultKafkaConsumerFactory<String, ProductCreated>(consumerProps);
        var container = new KafkaMessageListenerContainer<>(consumerFactory, 
            new ContainerProperties("products.created"));
        
        BlockingQueue<ConsumerRecord<String, ProductCreated>> records = new LinkedBlockingQueue<>();
        container.setupMessageListener((MessageListener<String, ProductCreated>) records::add);
        container.start();
        
        // Act: Crear producto
        ProductIdentifier productId = productCommandService.createProduct(
            "Test Product", "Description", new BigDecimal("99.99"), 10, "Electronics"
        );
        
        // Assert: Verificar que evento llegÃ³ a Kafka
        ConsumerRecord<String, ProductCreated> record = records.poll(10, TimeUnit.SECONDS);
        assertThat(record).isNotNull();
        assertThat(record.value().id()).isEqualTo(productId);
        assertThat(record.value().name()).isEqualTo("Test Product");
        
        // Cleanup
        container.stop();
    }
}
```

### Testing de Observabilidad

```java
// src/test/java/com/example/store/observability/TracingTest.java
package com.example.store.observability;

import com.example.store.products.command.ProductCommandService;
import io.micrometer.tracing.TraceContext;
import io.micrometer.tracing.Tracer;
import lombok.RequiredArgsConstructor;
import org.junit.jupiter.api.Test;
import org.springframework.modulith.test.ApplicationModuleTest;

import java.math.BigDecimal;

import static org.assertj.core.api.Assertions.assertThat;

/**
 * Test para verificar que la trazabilidad funciona correctamente.
 */
@ApplicationModuleTest
@RequiredArgsConstructor
class TracingTest {
    
    private final ProductCommandService productCommandService;
    private final Tracer tracer;
    
    @Test
    void shouldCreateTraceWhenCreatingProduct() {
        // Arrange: Verificar que no hay traza activa
        assertThat(tracer.currentTraceContext().context()).isNull();
        
        // Act: Crear producto dentro de una traza
        var span = tracer.nextSpan().name("test-create-product").start();
        try (Tracer.SpanInScope ws = tracer.withSpanInScope(span)) {
            TraceContext context = tracer.currentTraceContext().context();
            assertThat(context).isNotNull();
            
            productCommandService.createProduct(
                "Traced Product", "Description", new BigDecimal("49.99"), 5, "Test"
            );
            
            // Assert: Verificar que la traza sigue activa
            assertThat(tracer.currentTraceContext().context()).isEqualTo(context);
            
        } finally {
            span.end();
        }
    }
}
```

## Deployment con Docker

### Â¿QuÃ© es Docker?

**DefiniciÃ³n**: Docker es una plataforma que permite empaquetar aplicaciones y sus dependencias en contenedores.

**AnalogÃ­a**: Es como un "contenedor de envÃ­o" que garantiza que tu aplicaciÃ³n funcione igual en cualquier lugar.

### Â¿Por quÃ© Docker para Desarrollo?

#### Problemas Sin Docker

**"Funciona en Mi MÃ¡quina"**:
```
Desarrollador A: Java 17, PostgreSQL 14, Ubuntu
Desarrollador B: Java 11, PostgreSQL 13, Windows  
Servidor QA: Java 18, PostgreSQL 15, CentOS
ProducciÃ³n: Java 17, PostgreSQL 16, AWS Linux

Â¿Resultado? Comportamientos diferentes en cada ambiente
```

**InstalaciÃ³n Manual**:
```bash
# Cada desarrollador debe instalar:
- PostgreSQL (Â¿quÃ© versiÃ³n?)
- Kafka (Â¿cÃ³mo configurarlo?)  
- Zipkin (Â¿dÃ³nde descargarlo?)
- Java (Â¿OpenJDK vs Oracle?)
```

#### Ventajas con Docker

**Ambiente Consistente**:
```yaml
# Todos usan exactamente:
postgres:15-alpine    # Misma versiÃ³n de PostgreSQL
confluentinc/cp-kafka # Misma distribuciÃ³n de Kafka  
openzipkin/zipkin     # Misma versiÃ³n de Zipkin
```

**InstalaciÃ³n Simple**:
```bash
# Solo necesitas:
task dev              # Todo se instala automÃ¡ticamente
```

### Docker Compose Explicado

Crea `deployment/docker-compose.yml`:

```yaml
# deployment/docker-compose.yml
version: '3.8'

services:
  # =====================================
  # BASE DE DATOS
  # =====================================
  postgres:
    # Â¿QuÃ© es? Imagen oficial de PostgreSQL optimizada (Alpine = pequeÃ±a)
    image: postgres:15-alpine
    
    # Â¿QuÃ© es? Nombre del contenedor (para referenciarlo fÃ¡cilmente)
    container_name: store-postgres
    
    # Â¿QuÃ© son? Variables que PostgreSQL lee al iniciar
    environment:
      POSTGRES_DB: store_db          # Nombre de la base de datos
      POSTGRES_USER: store_user      # Usuario que crearÃ¡
      POSTGRES_PASSWORD: store_password  # ContraseÃ±a del usuario
    
    # Â¿QuÃ© hace? Mapea puerto del contenedor al host
    # host:contenedor -> localhost:5432 apunta al puerto 5432 del contenedor
    ports:
      - "5432:5432"
    
    # Â¿QuÃ© es? Almacenamiento persistente
    # Sin esto: Datos se pierden al borrar el contenedor
    volumes:
      - postgres_data:/var/lib/postgresql/data
    
    # Â¿QuÃ© hace? Verifica si el servicio estÃ¡ listo
    # Â¿Por quÃ©? Otros servicios esperan hasta que PostgreSQL responda
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U store_user -d store_db"]
      interval: 10s      # Cada 10 segundos
      timeout: 5s        # MÃ¡ximo 5 segundos de espera
      retries: 5         # MÃ¡ximo 5 intentos
    
    # Â¿QuÃ© es? Red virtual para que contenedores se comuniquen
    networks:
      - store-network

  # =====================================
  # TRAZABILIDAD
  # =====================================
  zipkin:
    # Â¿QuÃ© es? Imagen oficial de Zipkin para trazabilidad
    image: openzipkin/zipkin:latest
    container_name: store-zipkin
    
    ports:
      # Puerto estÃ¡ndar de Zipkin
      - "9411:9411"
    
    environment:
      # Â¿QuÃ© hace? Usa memoria en lugar de base de datos
      # Â¿Por quÃ©? MÃ¡s simple para desarrollo (datos no persisten)
      - STORAGE_TYPE=mem
    
    healthcheck:
      # Â¿CÃ³mo verifica? Hace peticiÃ³n HTTP al endpoint de salud
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9411/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - store-network

  # =====================================
  # KAFKA
  # =====================================
  zookeeper:
    # Â¿QuÃ© es Zookeeper? Servicio que Kafka necesita para coordinaciÃ³n
    # Â¿Por quÃ© lo necesitamos? Kafka depende de Ã©l (por ahora)
    image: confluentinc/cp-zookeeper:latest
    container_name: store-zookeeper
    environment:
      # Puerto estÃ¡ndar donde Kafka se conecta a Zookeeper
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - store-network

  kafka:
    # Â¿QuÃ© es? Imagen de Kafka de Confluent (empresa que mantiene Kafka)
    image: confluentinc/cp-kafka:latest
    container_name: store-kafka
    
    environment:
      # Â¿DÃ³nde estÃ¡ Zookeeper? (Kafka necesita esta info)
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      
      # Â¿CÃ³mo anunciar la direcciÃ³n? Clientes se conectan a localhost:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      
      # Â¿CuÃ¡ntas rÃ©plicas? 1 para desarrollo (normalmente 3 en producciÃ³n)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      
      # Â¿Crear tÃ³picos automÃ¡ticamente? SÃ­, para facilitar desarrollo
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    
    ports:
      - "9092:9092"    # Puerto estÃ¡ndar de Kafka
    
    # Â¿Orden de inicio? Kafka necesita que Zookeeper estÃ© listo primero
    depends_on:
      - zookeeper
    
    healthcheck:
      # Â¿CÃ³mo verificar? Listar tÃ³picos (si funciona, Kafka estÃ¡ listo)
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - store-network

  # =====================================
  # APLICACIÃ“N PRINCIPAL
  # =====================================
  app:
    # Â¿De dÃ³nde viene? Se construye con task build:image
    image: store-cqrs:latest
    container_name: store-app
    
    # Â¿Orden de inicio? App necesita que todos los servicios estÃ©n listos
    depends_on:
      postgres:
        condition: service_healthy    # Espera hasta que PostgreSQL responda
      zipkin:
        condition: service_healthy    # Espera hasta que Zipkin responda  
      kafka:
        condition: service_healthy    # Espera hasta que Kafka responda
    
    # Â¿ConfiguraciÃ³n? Variables que Spring Boot lee al iniciar
    environment:
      # Â¿QuÃ© profile? 'docker' tiene configuraciÃ³n especÃ­fica para contenedores
      SPRING_PROFILES_ACTIVE: docker
      
      # Â¿Base de datos? 'postgres' = nombre del servicio, no 'localhost'
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/store_db
      SPRING_DATASOURCE_USERNAME: store_user
      SPRING_DATASOURCE_PASSWORD: store_password
      
      # Â¿Zipkin? 'zipkin' = nombre del servicio en la red de Docker
      MANAGEMENT_ZIPKIN_TRACING_ENDPOINT: http://zipkin:9411/api/v2/spans
      
      # Â¿Kafka? 'kafka' = nombre del servicio  
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    
    ports:
      - "8080:8080"    # AplicaciÃ³n accesible en localhost:8080
    
    healthcheck:
      # Â¿EstÃ¡ lista? Verificar endpoint de salud de Spring Boot
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s    # Esperar 60s antes del primer check (app tarda en iniciar)
    networks:
      - store-network

# =====================================
# ALMACENAMIENTO PERSISTENTE
# =====================================
volumes:
  postgres_data:
    # Â¿QuÃ© es? Volumen administrado por Docker
    # Â¿Para quÃ©? Los datos de PostgreSQL sobreviven al borrar contenedores
    driver: local

# =====================================
# REDES
# =====================================
networks:
  store-network:
    # Â¿QuÃ© tipo? Bridge = red local donde contenedores se ven entre sÃ­
    # Â¿Por quÃ©? 'app' puede conectarse a 'postgres' por nombre
    driver: bridge
```

### Profile EspecÃ­fico para Docker

Crea `src/main/resources/application-docker.yml`:

```yaml
# application-docker.yml
# Â¿Para quÃ©? ConfiguraciÃ³n especÃ­fica cuando app corre en contenedor

spring:
  datasource:
    # Â¿Por quÃ© 'postgres'? En Docker, servicios se conectan por nombre
    url: jdbc:postgresql://postgres:5432/store_db
    username: store_user
    password: store_password
  
  kafka:
    # Â¿Por quÃ© 'kafka'? Nombre del servicio en docker-compose.yml
    bootstrap-servers: kafka:9092
  
management:
  zipkin:
    tracing:
      # Â¿Por quÃ© 'zipkin'? Nombre del servicio en la red de Docker
      endpoint: http://zipkin:9411/api/v2/spans

logging:
  level:
    # Â¿Por quÃ© INFO? En contenedores queremos menos logs
    com.example.store: INFO
```

## Demo Final

### Â¿QuÃ© Incluye el Demo?

**El demo muestra el flujo completo**:
1. **Crear producto** â†’ Ver evento interno + externo
2. **Agregar review** â†’ Ver actualizaciÃ³n de vista + Kafka
3. **Verificar trazabilidad** â†’ Zipkin muestra el flujo
4. **Validar mÃ³dulos** â†’ Endpoint de arquitectura

### Comandos del Demo

```bash
# 1. Demo completo automatizado
task demo

# Lo que hace internamente:
# - task build:image (construye app)
# - docker compose up (inicia todo)
# - Espera servicios listos
# - Muestra URLs importantes
```

### APIs para Probar Manualmente

```bash
# 1. Crear producto
curl -X POST http://localhost:8080/api/products \
  -H "Content-Type: application/json" \
  -d '{
    "name": "iPhone 15 Pro",
    "description": "Latest iPhone model",
    "price": 999.99,
    "stock": 50,
    "category": "Electronics"
  }'

# Respuesta esperada:
# {"id": "550e8400-e29b-41d4-a716-446655440000"}

# 2. Ver todos los productos
curl http://localhost:8080/api/products

# 3. Agregar review (reemplaza {id} con el ID real)
curl -X POST http://localhost:8080/api/products/{id}/reviews \
  -H "Content-Type: application/json" \
  -d '{
    "vote": 5,
    "comment": "Excelente producto!"
  }'

# 4. Ver productos ordenados por rating
curl http://localhost:8080/api/products/by-rating
```

### Â¿QuÃ© Verificar en el Demo?

#### 1. AplicaciÃ³n Funcionando
```bash
# Health check
curl http://localhost:8080/actuator/health

# Debe devolver:
{
  "status": "UP",
  "components": {
    "db": {"status": "UP"},
    "kafka": {"status": "UP"}
  }
}
```

#### 2. InformaciÃ³n de MÃ³dulos
```bash
# Ver estructura modular
curl http://localhost:8080/actuator/modulith

# Debe mostrar:
{
  "modules": [
    {"name": "products", "dependencies": ["common"]},
    {"name": "common", "dependencies": []}
  ],
  "violations": []  # â† Â¡Importante! Sin violaciones
}
```

#### 3. Trazabilidad en Zipkin
- **URL**: http://localhost:9411
- **QuÃ© buscar**: Trazas que muestran:
  ```
  POST /api/products
  â”œâ”€ ProductCommandService.createProduct
  â”œâ”€ ProductRepository.save
  â”œâ”€ ApplicationEventPublisher.publishEvent
  â””â”€ ProductEventHandler.on (async)
  ```

#### 4. Eventos en Kafka
```bash
# Ver tÃ³picos creados
docker exec store-kafka kafka-topics --bootstrap-server localhost:9092 --list

# Debe mostrar:
# products.created
# products.reviewed

# Consumir eventos (para ver quÃ© se enviÃ³)
docker exec store-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic products.created \
  --from-beginning

# Debe mostrar eventos JSON:
# {"id":"123","name":"iPhone 15 Pro",...}
```

### URLs del Demo

DespuÃ©s de `task demo`, estos endpoints estÃ¡n disponibles:

- **ğŸŒ AplicaciÃ³n**: http://localhost:8080
- **â¤ï¸ Health Check**: http://localhost:8080/actuator/health  
- **ğŸ—‚ï¸ InformaciÃ³n de MÃ³dulos**: http://localhost:8080/actuator/modulith
- **ğŸ“Š Trazas Zipkin**: http://localhost:9411

### Limpieza del Demo

```bash
# Detener demo (mantiene datos)
task demo:stop

# Limpiar completamente (borra datos)
task demo:clean
```

## ConclusiÃ³n del Workshop

### Â¿QuÃ© Hemos Logrado?

**âœ… Modularidad sin Complejidad**
- MÃ³dulos independientes dentro de un monolito
- Reglas arquitectÃ³nicas automÃ¡ticas
- Testing independiente por mÃ³dulo

**âœ… CQRS Funcional**  
- SeparaciÃ³n clara comandos vs queries
- Modelos optimizados para cada lado
- SincronizaciÃ³n automÃ¡tica vÃ­a eventos

**âœ… Observabilidad Completa**
- Trazabilidad como en microservicios
- InformaciÃ³n de mÃ³dulos en tiempo real
- Debugging simplificado

**âœ… IntegraciÃ³n Externa**
- Eventos a Kafka para otros sistemas
- Bajo acoplamiento entre aplicaciones
- Escalabilidad futura

**âœ… AutomatizaciÃ³n Total**
- Un comando inicia todo el entorno
- Docker garantiza consistencia
- Deployment simplificado

### Â¿CuÃ¡ndo Usar Spring Modulith?

**ğŸ‘ Ideal para:**
- Equipos de 2-10 desarrolladores
- Aplicaciones con dominios claros
- Necesidad de desarrollo rÃ¡pido
- Infraestructura limitada
- Monolitos existentes que mejorar

**ğŸ‘ No ideal para:**
- Equipos muy grandes (>20 personas)
- Dominios completamente independientes
- Requisitos de escalado muy especÃ­ficos
- TecnologÃ­as muy diferentes por Ã¡rea

### PrÃ³ximos Pasos

1. **Practicar**: Implementa mÃ¡s mÃ³dulos (`orders`, `inventory`)
2. **Profundizar**: Event Sourcing, Sagas, CQRS avanzado
3. **Optimizar**: Cache, performance, Ã­ndices BD
4. **Migrar**: Cuando llegue el momento, extraer mÃ³dulos a microservicios

### EvoluciÃ³n Gradual

**Fase 1: Monolito Modular** (donde estamos ahora)
- MÃ³dulos claros
- Eventos internos
- Testing independiente

**Fase 2: HÃ­brido** (cuando sea necesario)
- Algunos mÃ³dulos extraÃ­dos
- ComunicaciÃ³n vÃ­a Kafka
- Bases de datos separadas

**Fase 3: Microservicios** (solo si es necesario)
- Servicios completamente independientes
- Infraestructura compleja
- Equipos especializados

### Comandos de Referencia RÃ¡pida

```bash
# Desarrollo diario
task                    # Tests completos
task dev               # Entorno de desarrollo
task test:modulith     # Solo verificar arquitectura

# Demo y deployment  
task demo              # Demo completo
task build:image       # Construir imagen Docker
task infra:start       # Solo servicios base

# Limpieza
task demo:clean        # Limpiar demo
task infra:clean       # Limpiar infraestructura
```

**Recuerda**: No hay arquitectura perfecta, solo arquitectura adecuada para tu contexto actual.

Spring Modulith te da la flexibilidad de empezar simple y evolucionar segÃºn tus necesidades reales, no segÃºn las modas tecnolÃ³gicas.

Â¡Feliz codificaciÃ³n! ğŸ‰